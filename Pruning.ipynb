{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a4d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f40b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "[('bias', Parameter containing:\n",
      "tensor([ 0.0108, -0.0079,  0.1052,  0.0651,  0.0797, -0.2543],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.2941, -0.0804, -0.3134],\n",
      "          [-0.0099,  0.0290,  0.0828],\n",
      "          [ 0.3250, -0.1015,  0.1196]]],\n",
      "\n",
      "\n",
      "        [[[-0.1949, -0.1495,  0.2200],\n",
      "          [-0.0327, -0.0476, -0.2516],\n",
      "          [ 0.2741, -0.2347, -0.0397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1081, -0.2961, -0.1651],\n",
      "          [-0.1870, -0.3307,  0.1295],\n",
      "          [ 0.2603, -0.3210, -0.3223]]],\n",
      "\n",
      "\n",
      "        [[[-0.2598, -0.3015,  0.0519],\n",
      "          [-0.2764,  0.1571, -0.1859],\n",
      "          [-0.0807,  0.1851,  0.2222]]],\n",
      "\n",
      "\n",
      "        [[[-0.2159, -0.0311, -0.0404],\n",
      "          [-0.3136, -0.0617, -0.1504],\n",
      "          [ 0.2281,  0.0406,  0.0801]]],\n",
      "\n",
      "\n",
      "        [[[-0.0706, -0.2271, -0.0031],\n",
      "          [-0.0516, -0.1938,  0.0482],\n",
      "          [ 0.1937,  0.2082, -0.0860]]]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.conv1\n",
    "print(module)\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f4752b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03247bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 1., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 0., 1.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 1.]]]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af04dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2941, -0.0804, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.3250, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1949, -0.1495,  0.2200],\n",
      "          [-0.0327, -0.0476, -0.0000],\n",
      "          [ 0.2741, -0.2347, -0.0397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1081, -0.0000, -0.1651],\n",
      "          [-0.1870, -0.3307,  0.1295],\n",
      "          [ 0.2603, -0.3210, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2598, -0.0000,  0.0519],\n",
      "          [-0.2764,  0.0000, -0.1859],\n",
      "          [-0.0000,  0.1851,  0.2222]]],\n",
      "\n",
      "\n",
      "        [[[-0.2159, -0.0311, -0.0404],\n",
      "          [-0.3136, -0.0617, -0.1504],\n",
      "          [ 0.0000,  0.0406,  0.0801]]],\n",
      "\n",
      "\n",
      "        [[[-0.0706, -0.0000, -0.0031],\n",
      "          [-0.0000, -0.1938,  0.0000],\n",
      "          [ 0.1937,  0.2082, -0.0860]]]], grad_fn=<MulBackward0>)\n",
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x000002C114E7BA90>)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the weights are changed to zero by the pruning at random by 30%. We can see which weights are masked by printing named buffers\n",
    "print(module.weight)\n",
    "\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f525334",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.FloatTensor' object to parameter 'bias_orig' (torch.nn.Parameter or None required)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_unstructured\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\kai ji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\utils\\prune.py:923\u001b[0m, in \u001b[0;36ml1_unstructured\u001b[1;34m(module, name, amount, importance_scores)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ml1_unstructured\u001b[39m(module, name, amount, importance_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Prunes tensor corresponding to parameter called ``name`` in ``module``\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    by removing the specified `amount` of (currently unpruned) units with the\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03m    lowest L1-norm.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m        odict_keys(['bias', 'weight_orig', 'weight_mask'])\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m     \u001b[43mL1Unstructured\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportance_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimportance_scores\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[1;32mc:\\users\\kai ji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\utils\\prune.py:562\u001b[0m, in \u001b[0;36mL1Unstructured.apply\u001b[1;34m(cls, module, name, amount, importance_scores)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mcls\u001b[39m, module, name, amount, importance_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Adds the forward pre-hook that enables pruning on the fly and\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    the reparametrization of a tensor in terms of the original tensor\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m    and the pruning mask.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03m            If unspecified or None, the module parameter will be used in its place.\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mL1Unstructured\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportance_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimportance_scores\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\kai ji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\utils\\prune.py:173\u001b[0m, in \u001b[0;36mBasePruningMethod.apply\u001b[1;34m(cls, module, name, importance_scores, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# If this is the first time pruning is applied, take care of moving\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# the original tensor to a new parameter called name + '_orig' and\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# and deleting the original parameter\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(method, PruningContainer):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# copy `module[name]` to `module[name + '_orig']`\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_orig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# temporarily delete `module[name]`\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_parameters[name]\n",
      "File \u001b[1;32mc:\\users\\kai ji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:354\u001b[0m, in \u001b[0;36mModule.register_parameter\u001b[1;34m(self, name, param)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param, Parameter):\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object to parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(torch.nn.Parameter or None required)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(torch\u001b[38;5;241m.\u001b[39mtypename(param), name))\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad_fn:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot assign non-leaf Tensor to parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters must be created explicitly. To express \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas a function of another Tensor, compute the value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe forward() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot assign 'torch.FloatTensor' object to parameter 'bias_orig' (torch.nn.Parameter or None required)"
     ]
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name=\"bias\", amount=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ee3fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1949, -0.1495,  0.2200],\n",
      "          [-0.0327, -0.0476, -0.0000],\n",
      "          [ 0.2741, -0.2347, -0.0397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1081, -0.0000, -0.1651],\n",
      "          [-0.1870, -0.3307,  0.1295],\n",
      "          [ 0.2603, -0.3210, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2598, -0.0000,  0.0519],\n",
      "          [-0.2764,  0.0000, -0.1859],\n",
      "          [-0.0000,  0.1851,  0.2222]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "\n",
    "# As we can verify, this will zero out all the connections corresponding to\n",
    "# 50% (3 out of 6) of the channels, while preserving the action of the\n",
    "# previous mask.\n",
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9efbebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.nn.utils.prune.RandomUnstructured object at 0x000002C114E7BA90>, <torch.nn.utils.prune.LnStructured object at 0x000002C12CE5EA30>]\n"
     ]
    }
   ],
   "source": [
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == \"weight\":  # select out the correct hook\n",
    "        break\n",
    "\n",
    "print(list(hook))  # pruning history in the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da681cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7de90dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.2941, -0.0804, -0.3134],\n",
      "          [-0.0099,  0.0290,  0.0828],\n",
      "          [ 0.3250, -0.1015,  0.1196]]],\n",
      "\n",
      "\n",
      "        [[[-0.1949, -0.1495,  0.2200],\n",
      "          [-0.0327, -0.0476, -0.2516],\n",
      "          [ 0.2741, -0.2347, -0.0397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1081, -0.2961, -0.1651],\n",
      "          [-0.1870, -0.3307,  0.1295],\n",
      "          [ 0.2603, -0.3210, -0.3223]]],\n",
      "\n",
      "\n",
      "        [[[-0.2598, -0.3015,  0.0519],\n",
      "          [-0.2764,  0.1571, -0.1859],\n",
      "          [-0.0807,  0.1851,  0.2222]]],\n",
      "\n",
      "\n",
      "        [[[-0.2159, -0.0311, -0.0404],\n",
      "          [-0.3136, -0.0617, -0.1504],\n",
      "          [ 0.2281,  0.0406,  0.0801]]],\n",
      "\n",
      "\n",
      "        [[[-0.0706, -0.2271, -0.0031],\n",
      "          [-0.0516, -0.1938,  0.0482],\n",
      "          [ 0.1937,  0.2082, -0.0860]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([ 0.0108, -0.0079,  0.1052,  0.0651,  0.0797, -0.2543],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f9ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_orig', Parameter containing:\n",
      "tensor([ 0.0108, -0.0079,  0.1052,  0.0651,  0.0797, -0.2543],\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1949, -0.1495,  0.2200],\n",
      "          [-0.0327, -0.0476, -0.0000],\n",
      "          [ 0.2741, -0.2347, -0.0397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1081, -0.0000, -0.1651],\n",
      "          [-0.1870, -0.3307,  0.1295],\n",
      "          [ 0.2603, -0.3210, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2598, -0.0000,  0.0519],\n",
      "          [-0.2764,  0.0000, -0.1859],\n",
      "          [-0.0000,  0.1851,  0.2222]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01f7de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n"
     ]
    }
   ],
   "source": [
    "new_model = LeNet()\n",
    "for name, module in new_model.named_modules():\n",
    "  \n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.1)\n",
    " \n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "\n",
    "print(dict(new_model.named_buffers()).keys())  # to verify that all masks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6112b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 3.70%\n",
      "Sparsity in conv2.weight: 8.56%\n",
      "Sparsity in fc1.weight: 21.92%\n",
      "Sparsity in fc2.weight: 12.67%\n",
      "Sparsity in fc3.weight: 10.95%\n",
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv2.weight == 0))\n",
    "        / float(model.conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc1.weight == 0))\n",
    "        / float(model.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc2.weight == 0))\n",
    "        / float(model.fc2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc3.weight == 0))\n",
    "        / float(model.fc3.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "            + torch.sum(model.fc1.weight == 0)\n",
    "            + torch.sum(model.fc2.weight == 0)\n",
    "            + torch.sum(model.fc3.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "            + model.fc1.weight.nelement()\n",
    "            + model.fc2.weight.nelement()\n",
    "            + model.fc3.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88465688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "class FooBarPruningMethod(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        mask.view(-1)[::2] = 0\n",
    "        return mask\n",
    "    \n",
    "    \n",
    "def foobar_unstructured(module, name):\n",
    "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
    "    by removing every other entry in the tensors.\n",
    "    Modifies module in place (and also return the modified module)\n",
    "    by:\n",
    "    1) adding a named buffer called `name+'_mask'` corresponding to the\n",
    "    binary mask applied to the parameter `name` by the pruning method.\n",
    "    The parameter `name` is replaced by its pruned version, while the\n",
    "    original (unpruned) parameter is stored in a new parameter named\n",
    "    `name+'_orig'`.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): module containing the tensor to prune\n",
    "        name (string): parameter name within `module` on which pruning\n",
    "                will act.\n",
    "\n",
    "    Returns:\n",
    "        module (nn.Module): modified (i.e. pruned) version of the input\n",
    "            module\n",
    "\n",
    "    Examples:\n",
    "        >>> m = nn.Linear(3, 4)\n",
    "        >>> foobar_unstructured(m, name='bias')\n",
    "    \"\"\"\n",
    "    FooBarPruningMethod.apply(module, name)\n",
    "    return module\n",
    "\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "foobar_unstructured(model.fc3, name='bias')\n",
    "\n",
    "print(model.fc3.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0de00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
